# Deep Learning Image Classification Project

This project implements a CNN-based image classification system using either CIFAR-10 or Animals10 datasets. The project includes both custom CNN architectures and transfer learning approaches, with a complete Flask web application for deployment.

## ğŸ¯ Project Objectives

- Build and compare custom CNN architectures with transfer learning models
- Achieve >70% validation accuracy for passing grade
- Deploy the best model via Flask web application
- Provide comprehensive analysis and documentation

## ğŸ“ Project Structure

```
image_class_project_ih/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md    # AI coding assistant guidelines
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # Dataset analysis and visualization
â”‚   â”œâ”€â”€ 02_custom_cnn.ipynb       # Custom CNN implementation
â”‚   â””â”€â”€ 03_transfer_learning.ipynb # Transfer learning experiments
â”œâ”€â”€ src/                           # Python source modules
â”‚   â”œâ”€â”€ data_preprocessing.py      # Data loading and preprocessing
â”‚   â”œâ”€â”€ model_architectures.py     # CNN and transfer learning models
â”‚   â”œâ”€â”€ training_utils.py         # Training and evaluation utilities
â”‚   â””â”€â”€ train_model.py            # Command-line training script
â”œâ”€â”€ app/                          # Flask web application
â”‚   â”œâ”€â”€ app.py                    # Main Flask application
â”‚   â”œâ”€â”€ utils.py                  # Model loading and prediction utilities
â”‚   â”œâ”€â”€ templates/                # HTML templates
â”‚   â”‚   â”œâ”€â”€ upload.html           # Image upload interface
â”‚   â”‚   â””â”€â”€ results.html          # Results display
â”‚   â””â”€â”€ static/                   # CSS and static files
â”‚       â””â”€â”€ style.css             # Custom styling
â”œâ”€â”€ models/                       # Saved trained models
â”œâ”€â”€ data/                        # Dataset storage (gitignored)
â”œâ”€â”€ reports/                     # PDF reports and visualizations
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone <repository-url>
cd image_class_project_ih

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Data Exploration

Start with the data exploration notebook:

```bash
jupyter notebook notebooks/01_data_exploration.ipynb
```

### 3. Model Training

Train models using the notebooks or command-line script:

```bash
# Using command-line script
python src/train_model.py --model-type custom --dataset cifar10 --epochs 50
python src/train_model.py --model-type transfer --base-model vgg16 --dataset cifar10 --epochs 30
```

### 4. Web Application Deployment

Deploy the trained model via Flask:

```bash
cd app
python app.py --model ../models/best_model.h5 --dataset cifar10
```

Access the application at `http://localhost:5000`

## ğŸ“Š Datasets

### CIFAR-10

- **Images**: 60,000 (50,000 train + 10,000 test)
- **Size**: 32Ã—32 pixels, RGB
- **Classes**: 10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)
- **Download**: Automatically loaded via `tf.keras.datasets.cifar10`

### Animals10 (Alternative)

- **Images**: ~28,000
- **Classes**: 10 (dog, cat, horse, spider, butterfly, chicken, sheep, cow, squirrel, elephant)
- **Download**: [Kaggle Animals10 Dataset](https://www.kaggle.com/datasets/alessiocorrado99/animals10/data)

## ğŸ”§ Model Architectures

### Custom CNN

- **Architecture**: Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout
- **Blocks**: 3 convolutional blocks with increasing filters (32, 64, 128)
- **Head**: GlobalAveragePooling â†’ Dense(128) â†’ Dropout(0.5) â†’ Dense(classes)
- **Parameters**: ~500K

### Transfer Learning

- **Base Models**: VGG16, ResNet50, EfficientNetB0
- **Strategy**: Frozen base + custom classification head
- **Fine-tuning**: Unfreeze base layers with lower learning rate
- **Input Size**: 224Ã—224 (resized from original)

## ğŸ“ˆ Training Configuration

### Data Preprocessing

- **Normalization**: Pixel values scaled to [0, 1]
- **Augmentation**: Rotation (Â±15Â°), shifts (Â±10%), horizontal flip, zoom (Â±10%)
- **Splits**: 70% train / 15% validation / 15% test

### Training Parameters

- **Optimizer**: Adam (lr=0.001) or SGD with momentum
- **Loss**: Categorical crossentropy
- **Batch Size**: 32
- **Epochs**: 50-100 (custom CNN), 20-50 (transfer learning)
- **Callbacks**: Early stopping, model checkpoint, learning rate reduction

## ğŸ¯ Evaluation Metrics

- **Accuracy**: Overall classification accuracy
- **Per-class metrics**: Precision, recall, F1-score
- **Confusion Matrix**: Detailed classification analysis
- **Training curves**: Loss and accuracy over epochs

## ğŸŒ Web Application Features

### Upload Interface

- **Multi-file upload**: Drag & drop or browse
- **Preview**: Image thumbnails before processing
- **Validation**: File type and size checking

### Results Display

- **Predictions**: Top class with confidence score
- **Probabilities**: All class probabilities visualization
- **Export**: JSON/CSV results download
- **API**: RESTful endpoint for programmatic access

### API Usage

```bash
# Single prediction
curl -X POST -F "file=@image.jpg" http://localhost:5000/api/predict

# Response
{
  "prediction": "cat",
  "confidence": 0.89,
  "all_probabilities": {
    "cat": 0.89,
    "dog": 0.07,
    "bird": 0.02,
    ...
  }
}
```

## ğŸ“‹ Development Workflow

### 1. Data Analysis

```bash
jupyter notebook notebooks/01_data_exploration.ipynb
```

### 2. Custom CNN Development

```bash
jupyter notebook notebooks/02_custom_cnn.ipynb
```

### 3. Transfer Learning Experiments

```bash
jupyter notebook notebooks/03_transfer_learning.ipynb
```

### 4. Model Comparison

- Compare custom CNN vs transfer learning
- Select best performing model
- Document performance differences

### 5. Deployment

```bash
cd app
python app.py --model ../models/best_model.h5
```

## ğŸ† Success Criteria

- âœ… **Accuracy**: >70% validation accuracy (passing grade)
- âœ… **Architecture**: Both custom CNN and transfer learning implemented
- âœ… **Comparison**: Detailed performance analysis
- âœ… **Deployment**: Working Flask application
- âœ… **Documentation**: Comprehensive report and code documentation

## ğŸ” Model Performance Tracking

Track key metrics throughout development:

```python
# Example performance tracking
{
    "custom_cnn": {
        "validation_accuracy": 0.75,
        "test_accuracy": 0.73,
        "parameters": 512000,
        "training_time": "45 minutes"
    },
    "vgg16_transfer": {
        "validation_accuracy": 0.82,
        "test_accuracy": 0.80,
        "parameters": 15000000,
        "training_time": "25 minutes"
    }
}
```

## ğŸš€ Advanced Features

### Model Serving

- **TensorFlow Serving**: Production deployment option
- **Docker**: Containerized deployment
- **Cloud deployment**: AWS/GCP integration

### Performance Optimization

- **Model quantization**: Reduce model size
- **Batch prediction**: Efficient multi-image processing
- **Caching**: Model and prediction caching

## ğŸ“– Additional Resources

- [TensorFlow Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification)
- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Flask Deployment Best Practices](https://flask.palletsprojects.com/en/2.0.x/deploying/)

## ğŸ¤ Contributing

1. Follow the coding patterns in `.github/copilot-instructions.md`
2. Use the established project structure
3. Add tests for new functionality
4. Update documentation

## ğŸ“„ License

This project is for educational purposes as part of the Ironhack Data Science program.
