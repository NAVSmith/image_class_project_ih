{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9023292",
   "metadata": {},
   "source": [
    "# Custom CNN Architecture for Image Classification\n",
    "\n",
    "This notebook implements and trains a custom CNN architecture from scratch.\n",
    "\n",
    "## Objectives:\n",
    "- Design custom CNN architecture\n",
    "- Implement data preprocessing and augmentation\n",
    "- Train the model with proper validation\n",
    "- Evaluate performance and visualize results\n",
    "- Save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a473d",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cea7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU configured: 1 device(s) found\n",
      "TensorFlow version: 2.15.0\n",
      "Available devices: ['/physical_device:CPU:0', '/physical_device:GPU:0']\n",
      "âœ… Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Configure environment for Apple Silicon optimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Configure TensorFlow for Apple Silicon\n",
    "try:\n",
    "    # Enable memory growth for GPU (if available)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU configured: {len(gpus)} device(s) found\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸  No GPU found, using CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  GPU configuration warning: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available devices: {[device.name for device in tf.config.list_physical_devices()]}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "print(\"âœ… Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db73c0c",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bb04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/smithn5/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2'\n",
    "data_dir = os.path.join(path, 'raw-img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e3726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, and test sets physically in the data directory\n",
    "base_dir = '../data/'\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "img_height = 128 # for basic cnn\n",
    "img_width = 128 # for basic cnn\n",
    "\n",
    "# Create base directories for splits\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(base_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split and copy images\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    images = os.listdir(class_path)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    n_total = len(images)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    n_test = n_total - n_train - n_val  # Ensure all images are used\n",
    "\n",
    "    train_images = images[:n_train]\n",
    "    val_images = images[n_train:n_train+n_val]\n",
    "    test_images = images[n_train+n_val:]\n",
    "\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'train', class_name, img))\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'val', class_name, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'test', class_name, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d220e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Creating improved data generators...\n",
      "Found 20938 images belonging to 10 classes.\n",
      "Found 2614 images belonging to 10 classes.\n",
      "Found 2627 images belonging to 10 classes.\n",
      "Found 10 classes: ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "Training samples: 20938\n",
      "Validation samples: 2614\n",
      "Test samples: 2627\n",
      "Training batches per epoch: 655\n",
      "Validation batches per epoch: 82\n",
      "Test batches per epoch: 83\n",
      "Batch size: 32\n",
      "\n",
      "Class distribution check:\n",
      "  cane: 4863 images\n",
      "  cavallo: 2623 images\n",
      "  elefante: 1446 images\n",
      "  farfalla: 2112 images\n",
      "  gallina: 3098 images\n",
      "  gatto: 1668 images\n",
      "  mucca: 1866 images\n",
      "  pecora: 1820 images\n",
      "  ragno: 4821 images\n",
      "  scoiattolo: 1862 images\n",
      "\n",
      "Class balance analysis:\n",
      "  Min class size: 1446\n",
      "  Max class size: 4863\n",
      "  Imbalance ratio: 3.36\n",
      "âš¡ Moderate class imbalance detected\n",
      "\n",
      "âœ… Improved data generators created with:\n",
      "  - Reduced augmentation intensity\n",
      "  - Separate validation generator (no augmentation)\n",
      "  - Proper class balance verification\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "base_dir = '../data/'\n",
    "\n",
    "\n",
    "# ISSUE DIAGNOSIS: Your augmentation might be too aggressive!\n",
    "# Let's create a less aggressive augmentation setup\n",
    "\n",
    "print(\"ðŸ”§ Creating improved data generators...\")\n",
    "\n",
    "# Create LESS aggressive augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize to [0,1]\n",
    "    rotation_range=20,      # Reduced from 20\n",
    "    width_shift_range=0.2,  # Reduced from 0.2\n",
    "    height_shift_range=0.2, # Reduced from 0.2\n",
    "    shear_range=0.2,        # Reduced from 0.2\n",
    "    zoom_range=0.2,         # Reduced from 0.2\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create validation generator without augmentation (IMPORTANT!)\n",
    "test_val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Only rescaling for validation\n",
    ")\n",
    "\n",
    "# Create training dataset with augmentation\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'train'),\n",
    "    shuffle=True,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation dataset WITHOUT augmentation\n",
    "val_ds = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'val'),\n",
    "    shuffle=False,  # Don't shuffle validation\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#create test dataset WITHOUT augmentation\n",
    "test_ds = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'test'),\n",
    "    shuffle=False,  # Don't shuffle test\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get class names from the dataset\n",
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "# Calculate dataset sizes\n",
    "print(f\"Training samples: {train_ds.samples}\")\n",
    "print(f\"Validation samples: {val_ds.samples}\")\n",
    "print(f\"Test samples: {test_ds.samples}\")\n",
    "print(f\"Training batches per epoch: {len(train_ds)}\")\n",
    "print(f\"Validation batches per epoch: {len(val_ds)}\")\n",
    "print(f\"Test batches per epoch: {len(test_ds)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Verify class balance\n",
    "print(f\"\\nClass distribution check:\")\n",
    "class_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(path, 'raw-img', class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        count = len([f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        class_counts[class_name] = count\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "# Check for extremely imbalanced classes\n",
    "min_count = min(class_counts.values())\n",
    "max_count = max(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "print(f\"\\nClass balance analysis:\")\n",
    "print(f\"  Min class size: {min_count}\")\n",
    "print(f\"  Max class size: {max_count}\")\n",
    "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"âš ï¸  WARNING: Severe class imbalance detected!\")\n",
    "    print(\"   This could explain poor learning performance\")\n",
    "elif imbalance_ratio > 3:\n",
    "    print(\"âš¡ Moderate class imbalance detected\")\n",
    "else:\n",
    "    print(\"âœ… Classes are reasonably balanced\")\n",
    "\n",
    "print(f\"\\nâœ… Improved data generators created with:\")\n",
    "print(f\"  - Reduced augmentation intensity\")\n",
    "print(f\"  - Separate validation generator (no augmentation)\")\n",
    "print(f\"  - Proper class balance verification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec1e2bd",
   "metadata": {},
   "source": [
    "## 3. Custom CNN Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa2ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3305930 (12.61 MB)\n",
      "Trainable params: 3305930 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Model Details:\n",
      "Input shape: (128, 128, 3)\n",
      "Number of classes: 10\n",
      "Total parameters: 3,305,930\n",
      "Trainable parameters: 3,305,930\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "âœ… Model architecture diagram saved to '../models/simple_cnn_architecture.png'\n"
     ]
    }
   ],
   "source": [
    "def create_simple_cnn(input_shape, num_classes=10):\n",
    "    \"\"\"\n",
    "    Create a simple CNN model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (img_height, img_width, 3)\n",
    "num_classes = len(class_names)\n",
    "custom_model = create_simple_cnn(input_shape, num_classes)\n",
    "\n",
    "# Display model architecture\n",
    "custom_model.summary()\n",
    "\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Total parameters: {custom_model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in custom_model.trainable_weights]):,}\")\n",
    "\n",
    "# Visualize model architecture\n",
    "tf.keras.utils.plot_model(\n",
    "    custom_model,\n",
    "    to_file='../models/simple_cnn_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")\n",
    "print(\"âœ… Model architecture diagram saved to '../models/simple_cnn_architecture.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f069f0",
   "metadata": {},
   "source": [
    "## 4. Model Compilation and Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea466a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” DEBUGGING MODEL AND DATA...\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ðŸš€ STARTING IMPROVED TRAINING...\n",
      "==================================================\n",
      "âœ… Reduced learning rate to 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Let's first debug the data and model setup\n",
    "print(\"ðŸ” DEBUGGING MODEL AND DATA...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check data generators\n",
    "# print(\"Data Generator Check:\")\n",
    "# print(f\"Training samples: {train_ds.samples}\")\n",
    "# print(f\"Validation samples: {val_ds.samples}\")\n",
    "# print(f\"Classes found: {len(class_names)}\")\n",
    "# print(f\"Class names: {class_names}\")\n",
    "\n",
    "# # Test a batch to see if data looks correct\n",
    "# sample_batch_x, sample_batch_y = next(train_ds)\n",
    "# print(f\"\\nSample batch shapes:\")\n",
    "# print(f\"Images: {sample_batch_x.shape}\")\n",
    "# print(f\"Labels: {sample_batch_y.shape}\")\n",
    "# print(f\"Image value range: [{sample_batch_x.min():.3f}, {sample_batch_x.max():.3f}]\")\n",
    "# print(f\"Labels sum (should be 1 for each): {sample_batch_y.sum(axis=1)[:5]}\")\n",
    "# train_ds.reset()\n",
    "\n",
    "# # Check model output\n",
    "# print(f\"\\nModel check:\")\n",
    "# print(f\"Model expects input shape: {custom_model.input_shape}\")\n",
    "# print(f\"Model outputs shape: {custom_model.output_shape}\")\n",
    "# print(f\"Number of parameters: {custom_model.count_params():,}\")\n",
    "\n",
    "# # Test model prediction on one batch\n",
    "# test_pred = custom_model.predict(sample_batch_x[:1], verbose=0)\n",
    "# print(f\"Test prediction shape: {test_pred.shape}\")\n",
    "# print(f\"Test prediction sum: {test_pred.sum()} (should be ~1.0)\")\n",
    "# print(f\"Test prediction values: {test_pred[0][:5]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸš€ STARTING IMPROVED TRAINING...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# SOLUTION 1: Lower learning rate significantly\n",
    "custom_model.compile(\n",
    "    optimizer='adam', #tf.keras.optimizers.Adam(learning_rate=0.0001),  # Much lower LR\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"âœ… Reduced learning rate to 0.0001\")\n",
    "\n",
    "# SOLUTION 2: Improved callbacks with more aggressive learning rate reduction\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,  # Reduced patience\n",
    "        restore_best_weights=True,\n",
    "        # verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        '../models/custom_simple_animals10_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        # verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,  # More aggressive reduction\n",
    "        patience=3,  # slower response\n",
    "        min_lr=1e-6,\n",
    "        # verbose=1\n",
    "\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d267e",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295c42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved training setup:\n",
      "- Learning rate: 0.0001 (reduced from 0.001)\n",
      "- Max epochs: 35\n",
      "- Early stopping patience: 8\n",
      "- LR reduction factor: 0.2 (more aggressive)\n",
      "- Batch size: 32\n",
      "Epoch 1/35\n",
      "655/655 [==============================] - 44s 67ms/step - loss: 2.0562 - accuracy: 0.2795 - val_loss: 2.0299 - val_accuracy: 0.3630 - lr: 0.0010\n",
      "Epoch 2/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 1.9365 - accuracy: 0.3461 - val_loss: 1.7920 - val_accuracy: 0.3917 - lr: 0.0010\n",
      "Epoch 3/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 1.8969 - accuracy: 0.3592 - val_loss: 2.2155 - val_accuracy: 0.3359 - lr: 0.0010\n",
      "Epoch 4/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 1.8951 - accuracy: 0.3744 - val_loss: 2.1095 - val_accuracy: 0.3795 - lr: 0.0010\n",
      "Epoch 5/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 1.9120 - accuracy: 0.3896 - val_loss: 1.6017 - val_accuracy: 0.4698 - lr: 0.0010\n",
      "Epoch 6/35\n",
      "655/655 [==============================] - 43s 65ms/step - loss: 1.8995 - accuracy: 0.4000 - val_loss: 1.6365 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 7/35\n",
      "655/655 [==============================] - 333s 509ms/step - loss: 2.0035 - accuracy: 0.3995 - val_loss: 2.0083 - val_accuracy: 0.4468 - lr: 0.0010\n",
      "Epoch 8/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 2.1699 - accuracy: 0.3990 - val_loss: 2.1288 - val_accuracy: 0.4258 - lr: 0.0010\n",
      "Epoch 9/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 1.9716 - accuracy: 0.4290 - val_loss: 2.1500 - val_accuracy: 0.4549 - lr: 5.0000e-04\n",
      "Epoch 10/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 2.1804 - accuracy: 0.4156 - val_loss: 3.1393 - val_accuracy: 0.3294 - lr: 5.0000e-04\n",
      "Epoch 11/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 2.4200 - accuracy: 0.4069 - val_loss: 2.6340 - val_accuracy: 0.4246 - lr: 5.0000e-04\n",
      "Epoch 12/35\n",
      "655/655 [==============================] - 43s 66ms/step - loss: 2.1452 - accuracy: 0.4345 - val_loss: 3.4449 - val_accuracy: 0.3994 - lr: 2.5000e-04\n",
      "Epoch 13/35\n",
      "655/655 [==============================] - 44s 66ms/step - loss: 2.2910 - accuracy: 0.4299 - val_loss: 3.8889 - val_accuracy: 0.3849 - lr: 2.5000e-04\n",
      "Epoch 14/35\n",
      "655/655 [==============================] - 1037s 2s/step - loss: 2.3808 - accuracy: 0.4257 - val_loss: 3.7088 - val_accuracy: 0.4070 - lr: 2.5000e-04\n",
      "Epoch 15/35\n",
      "655/655 [==============================] - 6260s 10s/step - loss: 2.2450 - accuracy: 0.4437 - val_loss: 4.1584 - val_accuracy: 0.4002 - lr: 1.2500e-04\n",
      "\n",
      "âœ… Training completed!\n",
      "Total epochs trained: 15\n",
      "Best validation accuracy: 0.5038\n",
      "Final training accuracy: 0.4437\n",
      "Final validation accuracy: 0.4002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training parameters\n",
    "EPOCHS = 35  # Increased epochs since we lowered LR\n",
    "\n",
    "print(f\"Improved training setup:\")\n",
    "print(f\"- Learning rate: 0.0001 (reduced from 0.001)\")\n",
    "print(f\"- Max epochs: {EPOCHS}\")\n",
    "print(f\"- Early stopping patience: 8\")\n",
    "print(f\"- LR reduction factor: 0.2 (more aggressive)\")\n",
    "print(f\"- Batch size: {batch_size}\")\n",
    "\n",
    "# Train with improved settings\n",
    "history = custom_model.fit(\n",
    "    train_ds,\n",
    "    #steps_per_epoch=len(train_ds),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    #validation_steps=len(val_ds),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")\n",
    "if len(history.history['accuracy']) > 0:\n",
    "    print(f\"Total epochs trained: {len(history.history['accuracy'])}\")\n",
    "    print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "# Reset generators for future use\n",
    "train_ds.reset()\n",
    "val_ds.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a939daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30640069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "a = tf.random.normal([1024, 1024])\n",
    "b = tf.random.normal([1024, 1024])\n",
    "c = tf.matmul(a, b)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, tensorflow as tf\n",
    "@tf.function\n",
    "def step(x, y):\n",
    "    return tf.matmul(x, y)\n",
    "x = tf.random.normal([2048, 2048])\n",
    "y = tf.random.normal([2048, 2048])\n",
    "# warmup\n",
    "for _ in range(5): step(x, y)\n",
    "t0 = time.time()\n",
    "for _ in range(10): step(x, y)\n",
    "print(\"sec per step:\", (time.time()-t0)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2728aa52",
   "metadata": {},
   "source": [
    "## 6. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565976c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics with enhanced visualizations.\n",
    "    \"\"\"\n",
    "    # Create a larger figure with more subplots\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    ax1.plot(epochs, history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2, marker='o', markersize=4)\n",
    "    ax1.plot(epochs, history.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2, marker='s', markersize=4)\n",
    "    ax1.set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim([0, 1])\n",
    "    \n",
    "    # Add best accuracy annotation\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    best_val_acc_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
    "    ax1.annotate(f'Best: {best_val_acc:.3f}', \n",
    "                xy=(best_val_acc_epoch, best_val_acc), \n",
    "                xytext=(best_val_acc_epoch + 2, best_val_acc - 0.05),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', alpha=0.7))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(epochs, history.history['loss'], 'b-', label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "    ax2.plot(epochs, history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "    ax2.set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot learning rate (if available)\n",
    "    if 'lr' in history.history:\n",
    "        ax3.plot(epochs, history.history['lr'], 'g-', label='Learning Rate', linewidth=2)\n",
    "        ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('Learning Rate')\n",
    "        ax3.set_yscale('log')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        # Plot accuracy difference (overfitting indicator)\n",
    "        acc_diff = np.array(history.history['accuracy']) - np.array(history.history['val_accuracy'])\n",
    "        ax3.plot(epochs, acc_diff, 'purple', label='Training - Validation Accuracy', linewidth=2)\n",
    "        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax3.set_title('Overfitting Indicator', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('Accuracy Difference')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot smoothed validation accuracy trend\n",
    "    if len(history.history['val_accuracy']) > 5:\n",
    "        # Simple moving average\n",
    "        window_size = min(5, len(history.history['val_accuracy']) // 3)\n",
    "        val_acc_smooth = np.convolve(history.history['val_accuracy'], \n",
    "                                   np.ones(window_size)/window_size, mode='valid')\n",
    "        smooth_epochs = range(window_size, len(history.history['val_accuracy']) + 1)\n",
    "        \n",
    "        ax4.plot(epochs, history.history['val_accuracy'], 'lightcoral', alpha=0.5, label='Raw Validation Accuracy')\n",
    "        ax4.plot(smooth_epochs, val_acc_smooth, 'darkred', linewidth=3, label=f'Smoothed (window={window_size})')\n",
    "        ax4.set_title('Validation Accuracy Trend', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Validation Accuracy')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_ylim([0, 1])\n",
    "    else:\n",
    "        # If not enough epochs, show final metrics summary\n",
    "        ax4.text(0.1, 0.8, 'Training Summary', fontsize=16, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.1, 0.6, f'Epochs: {len(epochs)}', fontsize=12, transform=ax4.transAxes)\n",
    "        ax4.text(0.1, 0.5, f'Best Val Acc: {best_val_acc:.4f}', fontsize=12, transform=ax4.transAxes)\n",
    "        ax4.text(0.1, 0.4, f'Final Train Acc: {history.history[\"accuracy\"][-1]:.4f}', fontsize=12, transform=ax4.transAxes)\n",
    "        ax4.text(0.1, 0.3, f'Final Val Acc: {history.history[\"val_accuracy\"][-1]:.4f}', fontsize=12, transform=ax4.transAxes)\n",
    "        ax4.set_xlim(0, 1)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print comprehensive metrics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING HISTORY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total epochs trained: {len(epochs)}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f} at epoch {best_val_acc_epoch}\")\n",
    "    print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    \n",
    "    # Calculate overfitting metrics\n",
    "    final_gap = history.history['accuracy'][-1] - history.history['val_accuracy'][-1]\n",
    "    print(f\"\\nOverfitting Analysis:\")\n",
    "    print(f\"Final accuracy gap: {final_gap:.4f}\")\n",
    "    if final_gap > 0.1:\n",
    "        print(\"âš ï¸  Potential overfitting detected (gap > 0.1)\")\n",
    "    elif final_gap > 0.05:\n",
    "        print(\"âš¡ Mild overfitting (gap > 0.05)\")\n",
    "    else:\n",
    "        print(\"âœ… Good generalization (gap â‰¤ 0.05)\")\n",
    "    \n",
    "    # Training stability\n",
    "    last_5_val_acc = history.history['val_accuracy'][-5:] if len(history.history['val_accuracy']) >= 5 else history.history['val_accuracy']\n",
    "    val_acc_std = np.std(last_5_val_acc)\n",
    "    print(f\"Validation accuracy stability (last 5 epochs std): {val_acc_std:.4f}\")\n",
    "    \n",
    "    if val_acc_std < 0.01:\n",
    "        print(\"âœ… Training converged well\")\n",
    "    elif val_acc_std < 0.02:\n",
    "        print(\"âš¡ Training mostly stable\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Training still fluctuating\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e23fb",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3445bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (since we don't have a separate test set)\n",
    "val_ds.reset()\n",
    "val_loss, val_accuracy = custom_model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Generate predictions on validation set\n",
    "print(\"Generating predictions...\")\n",
    "val_ds.reset()\n",
    "y_pred = custom_model.predict(val_ds, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels from validation generator\n",
    "val_ds.reset()\n",
    "y_true_classes = []\n",
    "for i in range(len(val_ds)):\n",
    "    batch_images, batch_labels = next(val_ds)\n",
    "    batch_true_classes = np.argmax(batch_labels, axis=1)\n",
    "    y_true_classes.extend(batch_true_classes)\n",
    "\n",
    "y_true_classes = np.array(y_true_classes)\n",
    "\n",
    "# Ensure we have the same number of predictions and true labels\n",
    "min_length = min(len(y_pred_classes), len(y_true_classes))\n",
    "y_pred_classes = y_pred_classes[:min_length]\n",
    "y_true_classes = y_true_classes[:min_length]\n",
    "\n",
    "print(f\"Number of samples evaluated: {min_length}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Reset generator\n",
    "val_ds.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ae274",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d38999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Custom CNN')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {class_accuracy[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43257cc",
   "metadata": {},
   "source": [
    "## 9. Model Saving and Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy saving and documentation\n",
    "val_accuracy_str = f\"{val_accuracy:.2f}\".replace('.', '_')\n",
    "# Save the final model\n",
    "model_filename = f'../models/custom_costum_animals10_acc_{val_accuracy_str}.h5'\n",
    "custom_model.save(model_filename)\n",
    "print(f\"Model saved as: {model_filename}\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open(f'../models/custom_costum_animals10_acc_{val_accuracy_str}_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(f\"Training history saved\")\n",
    "\n",
    "# Save model configuration\n",
    "model_config = {\n",
    "    'model_name': 'Custom CNN',\n",
    "    'dataset': 'Animals10',\n",
    "    'input_shape': input_shape,\n",
    "    'num_classes': num_classes,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs_trained': len(history.history['accuracy']),\n",
    "    'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "    'final_val_accuracy': val_accuracy,\n",
    "    'total_parameters': custom_model.count_params(),\n",
    "    'architecture': 'VGG16-inspired with Global Average Pooling'\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'../models/custom_costum_animals10_acc_{val_accuracy_str}_config.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n",
    "# Results summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CUSTOM CNN RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: Animals10\")\n",
    "print(f\"Architecture: Custom CNN with {custom_model.count_params():,} parameters\")\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Training epochs: {len(history.history['accuracy'])}\")\n",
    "print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"Final validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Model saved: {model_filename}\")\n",
    "print(f\"Architecture follows CNN pattern:\")\n",
    "print(f\"  - 5 convolutional blocks (64â†’128â†’256â†’512â†’512 filters)\")\n",
    "print(f\"  - Global Average Pooling instead of FC layers\")\n",
    "print(f\"  - Dense(512) + Dense({num_classes}) classifier\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122994dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
