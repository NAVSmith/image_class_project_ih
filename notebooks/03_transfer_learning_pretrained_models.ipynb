{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a0c5bf",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification\n",
    "\n",
    "This notebook implements transfer learning using pre-trained models (VGG16, ResNet50, EfficientNet).\n",
    "\n",
    "## Objectives:\n",
    "- Compare multiple pre-trained architectures\n",
    "- Implement transfer learning with frozen base layers\n",
    "- Fine-tune the best performing model\n",
    "- Compare results with custom CNN\n",
    "- Select the best overall model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fffe3",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120676e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU configured: 1 device(s) found\n",
      "TensorFlow version: 2.15.0\n",
      "Available devices: ['/physical_device:CPU:0', '/physical_device:GPU:0']\n",
      "‚úÖ Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Configure environment for Apple Silicon optimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# import pre-trained models\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB7\n",
    "# Configure TensorFlow for Apple Silicon\n",
    "try:\n",
    "    # Enable memory growth for GPU (if available)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s) found\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  No GPU found, using CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  GPU configuration warning: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available devices: {[device.name for device in tf.config.list_physical_devices()]}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "print(\"‚úÖ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a31c59",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee2f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/smithn5/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2'\n",
    "data_dir = os.path.join(path, 'raw-img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a84a0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, and test sets physically in the data directory\n",
    "base_dir = '../data/'\n",
    "train_ratio = 0.9\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.00\n",
    "batch_size = 32\n",
    "\n",
    "img_height = 224 # for basic cnn\n",
    "img_width = 224 # for basic cnn\n",
    "\n",
    "# Create base directories for splits\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(base_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c1d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split and copy images\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    images = os.listdir(class_path)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    n_total = len(images)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    n_test = n_total - n_train - n_val  # Ensure all images are used\n",
    "\n",
    "    train_images = images[:n_train]\n",
    "    val_images = images[n_train:n_train+n_val]\n",
    "    test_images = images[n_train+n_val:]\n",
    "\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'train', class_name, img))\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'val', class_name, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'test', class_name, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b91451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating improved data generators...\n",
      "Found 23556 images belonging to 10 classes.\n",
      "Found 23556 images belonging to 10 classes.\n",
      "Found 2614 images belonging to 10 classes.\n",
      "Found 9 images belonging to 10 classes.\n",
      "Found 2614 images belonging to 10 classes.\n",
      "Found 9 images belonging to 10 classes.\n",
      "Found 10 classes: ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "Training samples: 23556\n",
      "Validation samples: 2614\n",
      "Test samples: 9\n",
      "Training batches per epoch: 737\n",
      "Validation batches per epoch: 82\n",
      "Test batches per epoch: 1\n",
      "Batch size: 32\n",
      "\n",
      "Class distribution check:\n",
      "  cane: 4863 images\n",
      "  cavallo: 2623 images\n",
      "  elefante: 1446 images\n",
      "  farfalla: 2112 images\n",
      "  gallina: 3098 images\n",
      "  gatto: 1668 images\n",
      "  mucca: 1866 images\n",
      "  pecora: 1820 images\n",
      "  ragno: 4821 images\n",
      "  scoiattolo: 1862 images\n",
      "\n",
      "Class balance analysis:\n",
      "  Min class size: 1446\n",
      "  Max class size: 4863\n",
      "  Imbalance ratio: 3.36\n",
      "‚ö° Moderate class imbalance detected\n",
      "\n",
      "‚úÖ Improved data generators created with:\n",
      "  - Reduced augmentation intensity\n",
      "  - Separate validation generator (no augmentation)\n",
      "  - Proper class balance verification\n",
      "Found 10 classes: ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "Training samples: 23556\n",
      "Validation samples: 2614\n",
      "Test samples: 9\n",
      "Training batches per epoch: 737\n",
      "Validation batches per epoch: 82\n",
      "Test batches per epoch: 1\n",
      "Batch size: 32\n",
      "\n",
      "Class distribution check:\n",
      "  cane: 4863 images\n",
      "  cavallo: 2623 images\n",
      "  elefante: 1446 images\n",
      "  farfalla: 2112 images\n",
      "  gallina: 3098 images\n",
      "  gatto: 1668 images\n",
      "  mucca: 1866 images\n",
      "  pecora: 1820 images\n",
      "  ragno: 4821 images\n",
      "  scoiattolo: 1862 images\n",
      "\n",
      "Class balance analysis:\n",
      "  Min class size: 1446\n",
      "  Max class size: 4863\n",
      "  Imbalance ratio: 3.36\n",
      "‚ö° Moderate class imbalance detected\n",
      "\n",
      "‚úÖ Improved data generators created with:\n",
      "  - Reduced augmentation intensity\n",
      "  - Separate validation generator (no augmentation)\n",
      "  - Proper class balance verification\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "base_dir = '../data/'\n",
    "\n",
    "\n",
    "# ISSUE DIAGNOSIS: Your augmentation might be too aggressive!\n",
    "# Let's create a less aggressive augmentation setup\n",
    "\n",
    "print(\"üîß Creating improved data generators...\")\n",
    "\n",
    "# Create LESS aggressive augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "     preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    "    # rescale=1./255,  # Normalize to [0,1]\n",
    "    # rotation_range=20,      # Reduced from 20\n",
    "    # width_shift_range=0.2,  # Reduced from 0.2\n",
    "    # height_shift_range=0.2, # Reduced from 0.2\n",
    "    # shear_range=0.2,     # Reduced from 0.2\n",
    "    # zoom_range=0.2,         # Reduced from 0.2\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create validation generator without augmentation (IMPORTANT!)\n",
    "test_val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    "    # rescale=1./255,  # Only rescaling for validation\n",
    "    # rotation_range=20,      # Reduced from 20\n",
    "    # width_shift_range=0.2,  # Reduced from 0.2\n",
    "    # height_shift_range=0.2, # Reduced from 0.2\n",
    "    # shear_range=0.2,     # Reduced from 0.2\n",
    "    # zoom_range=0.2,         # Reduced from 0.2\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create training dataset with augmentation\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'train'),\n",
    "    shuffle=True,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation dataset WITHOUT augmentation\n",
    "val_ds = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'val'),\n",
    "    shuffle=False,  # Don't shuffle validation\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#create test dataset WITHOUT augmentation\n",
    "test_ds = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'test'),\n",
    "    shuffle=False,  # Don't shuffle test\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get class names from the dataset\n",
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "# Calculate dataset sizes\n",
    "print(f\"Training samples: {train_ds.samples}\")\n",
    "print(f\"Validation samples: {val_ds.samples}\")\n",
    "print(f\"Test samples: {test_ds.samples}\")\n",
    "print(f\"Training batches per epoch: {len(train_ds)}\")\n",
    "print(f\"Validation batches per epoch: {len(val_ds)}\")\n",
    "print(f\"Test batches per epoch: {len(test_ds)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Verify class balance\n",
    "print(f\"\\nClass distribution check:\")\n",
    "class_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(path, 'raw-img', class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        count = len([f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        class_counts[class_name] = count\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "# Check for extremely imbalanced classes\n",
    "min_count = min(class_counts.values())\n",
    "max_count = max(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "print(f\"\\nClass balance analysis:\")\n",
    "print(f\"  Min class size: {min_count}\")\n",
    "print(f\"  Max class size: {max_count}\")\n",
    "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Severe class imbalance detected!\")\n",
    "    print(\"   This could explain poor learning performance\")\n",
    "elif imbalance_ratio > 3:\n",
    "    print(\"‚ö° Moderate class imbalance detected\")\n",
    "else:\n",
    "    print(\"‚úÖ Classes are reasonably balanced\")\n",
    "\n",
    "print(f\"\\n‚úÖ Improved data generators created with:\")\n",
    "print(f\"  - Reduced augmentation intensity\")\n",
    "print(f\"  - Separate validation generator (no augmentation)\")\n",
    "print(f\"  - Proper class balance verification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e890e31",
   "metadata": {},
   "source": [
    "## 3. Transfer Learning Model Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b3e242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning model creation functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_model(base_model_name, input_shape, num_classes, trainable=False):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model with specified base architecture.\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: 'vgg16', 'resnet50', or 'efficientnet'\n",
    "        input_shape: Input image shape\n",
    "        num_classes: Number of output classes\n",
    "        trainable: Whether to make base model trainable (for fine-tuning)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select base model\n",
    "    if base_model_name == 'vgg16':\n",
    "        base_model = VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name == 'resnet50':\n",
    "        base_model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name == 'efficientnet':\n",
    "        base_model = EfficientNetB7(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling='max'\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze or unfreeze base model\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        #layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.45),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.45),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "print(\"Transfer learning model creation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6ee9",
   "metadata": {},
   "source": [
    "## 4. Compare Multiple Pre-trained Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02174a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will compare 1 architectures...\n"
     ]
    }
   ],
   "source": [
    "# Model configurations to compare\n",
    "model_configs = [\n",
    "   # {'name': 'vgg16', 'display_name': 'VGG16'},\n",
    "   # {'name': 'resnet50', 'display_name': 'ResNet50'},\n",
    "    {'name': 'efficientnet', 'display_name': 'EfficientNetB7'}\n",
    "]\n",
    "\n",
    "print(f\"Will compare {len(model_configs)} architectures...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b929695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "- Input shape: (224, 224, 3)\n",
      "- Number of classes: 10\n",
      "- Epochs: 40\n",
      "- Learning rate: 1e-05\n",
      "- Batch size: 32\n",
      "\n",
      "============================================================\n",
      "Training EfficientNetB7\n",
      "============================================================\n",
      "Model created:\n",
      "- Total parameters: 64,462,625\n",
      "- Trainable parameters: 364,170\n",
      "- Frozen parameters: 64,097,687\n",
      "Starting training...\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional  (None, 2560)              64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               327808    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "Model created:\n",
      "- Total parameters: 64,462,625\n",
      "- Trainable parameters: 364,170\n",
      "- Frozen parameters: 64,097,687\n",
      "Starting training...\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional  (None, 2560)              64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               327808    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64462625 (245.91 MB)\n",
      "Trainable params: 364170 (1.39 MB)\n",
      "Non-trainable params: 64098455 (244.52 MB)\n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "Total params: 64462625 (245.91 MB)\n",
      "Trainable params: 364170 (1.39 MB)\n",
      "Non-trainable params: 64098455 (244.52 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "Epoch 1/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8971\n",
      "Epoch 1: val_loss improved from inf to 0.13348, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.13348, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 840s 1s/step - loss: 0.3645 - accuracy: 0.8971 - val_loss: 0.1335 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "737/737 [==============================] - 840s 1s/step - loss: 0.3645 - accuracy: 0.8971 - val_loss: 0.1335 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "Epoch 2/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9300\n",
      "Epoch 2: val_loss did not improve from 0.13348\n",
      "737/737 [==============================] - 777s 1s/step - loss: 0.2414 - accuracy: 0.9300 - val_loss: 0.1493 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.13348\n",
      "737/737 [==============================] - 777s 1s/step - loss: 0.2414 - accuracy: 0.9300 - val_loss: 0.1493 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "Epoch 3/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9336\n",
      "Epoch 3: val_loss improved from 0.13348 to 0.13151, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.13348 to 0.13151, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 803s 1s/step - loss: 0.2234 - accuracy: 0.9336 - val_loss: 0.1315 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "737/737 [==============================] - 803s 1s/step - loss: 0.2234 - accuracy: 0.9336 - val_loss: 0.1315 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "Epoch 4/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9379\n",
      "Epoch 4: val_loss improved from 0.13151 to 0.11244, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.13151 to 0.11244, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 784s 1s/step - loss: 0.2066 - accuracy: 0.9379 - val_loss: 0.1124 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "737/737 [==============================] - 784s 1s/step - loss: 0.2066 - accuracy: 0.9379 - val_loss: 0.1124 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9397\n",
      "Epoch 5: val_loss improved from 0.11244 to 0.10829, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.11244 to 0.10829, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 785s 1s/step - loss: 0.1983 - accuracy: 0.9397 - val_loss: 0.1083 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "737/737 [==============================] - 785s 1s/step - loss: 0.1983 - accuracy: 0.9397 - val_loss: 0.1083 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "Epoch 6/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.9398\n",
      "Epoch 6: val_loss did not improve from 0.10829\n",
      "737/737 [==============================] - 762s 1s/step - loss: 0.2020 - accuracy: 0.9398 - val_loss: 0.1182 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.10829\n",
      "737/737 [==============================] - 762s 1s/step - loss: 0.2020 - accuracy: 0.9398 - val_loss: 0.1182 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "Epoch 7/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9420\n",
      "Epoch 7: val_loss did not improve from 0.10829\n",
      "737/737 [==============================] - 1048s 1s/step - loss: 0.1936 - accuracy: 0.9420 - val_loss: 0.1277 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.10829\n",
      "737/737 [==============================] - 1048s 1s/step - loss: 0.1936 - accuracy: 0.9420 - val_loss: 0.1277 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "Epoch 8/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9435\n",
      "Epoch 8: val_loss improved from 0.10829 to 0.10592, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.10829 to 0.10592, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 705s 956ms/step - loss: 0.1870 - accuracy: 0.9435 - val_loss: 0.1059 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "737/737 [==============================] - 705s 956ms/step - loss: 0.1870 - accuracy: 0.9435 - val_loss: 0.1059 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "Epoch 9/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9449\n",
      "Epoch 9: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 704s 955ms/step - loss: 0.1830 - accuracy: 0.9449 - val_loss: 0.1127 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 704s 955ms/step - loss: 0.1830 - accuracy: 0.9449 - val_loss: 0.1127 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "Epoch 10/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9445\n",
      "Epoch 10: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 1654s 2s/step - loss: 0.1848 - accuracy: 0.9445 - val_loss: 0.1062 - val_accuracy: 0.9748 - lr: 0.0010\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 1654s 2s/step - loss: 0.1848 - accuracy: 0.9445 - val_loss: 0.1062 - val_accuracy: 0.9748 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "Epoch 11/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9454\n",
      "Epoch 11: val_loss did not improve from 0.10592\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1775 - accuracy: 0.9454 - val_loss: 0.1062 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.10592\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1775 - accuracy: 0.9454 - val_loss: 0.1062 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "Epoch 12/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9501\n",
      "Epoch 12: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 679s 921ms/step - loss: 0.1587 - accuracy: 0.9501 - val_loss: 0.1069 - val_accuracy: 0.9686 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.10592\n",
      "737/737 [==============================] - 679s 921ms/step - loss: 0.1587 - accuracy: 0.9501 - val_loss: 0.1069 - val_accuracy: 0.9686 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9515\n",
      "Epoch 13: val_loss improved from 0.10592 to 0.10124, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.10592 to 0.10124, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 682s 925ms/step - loss: 0.1588 - accuracy: 0.9515 - val_loss: 0.1012 - val_accuracy: 0.9717 - lr: 5.0000e-04\n",
      "737/737 [==============================] - 682s 925ms/step - loss: 0.1588 - accuracy: 0.9515 - val_loss: 0.1012 - val_accuracy: 0.9717 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "Epoch 14/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9522\n",
      "Epoch 14: val_loss did not improve from 0.10124\n",
      "737/737 [==============================] - 678s 920ms/step - loss: 0.1535 - accuracy: 0.9522 - val_loss: 0.1031 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.10124\n",
      "737/737 [==============================] - 678s 920ms/step - loss: 0.1535 - accuracy: 0.9522 - val_loss: 0.1031 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9548\n",
      "Epoch 15: val_loss improved from 0.10124 to 0.09941, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.10124 to 0.09941, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 682s 926ms/step - loss: 0.1477 - accuracy: 0.9548 - val_loss: 0.0994 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "737/737 [==============================] - 682s 926ms/step - loss: 0.1477 - accuracy: 0.9548 - val_loss: 0.0994 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9539\n",
      "Epoch 16: val_loss did not improve from 0.09941\n",
      "737/737 [==============================] - 679s 922ms/step - loss: 0.1494 - accuracy: 0.9539 - val_loss: 0.1021 - val_accuracy: 0.9702 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.09941\n",
      "737/737 [==============================] - 679s 922ms/step - loss: 0.1494 - accuracy: 0.9539 - val_loss: 0.1021 - val_accuracy: 0.9702 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "Epoch 17/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9543\n",
      "Epoch 17: val_loss improved from 0.09941 to 0.09934, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.09941 to 0.09934, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 681s 924ms/step - loss: 0.1462 - accuracy: 0.9543 - val_loss: 0.0993 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "737/737 [==============================] - 681s 924ms/step - loss: 0.1462 - accuracy: 0.9543 - val_loss: 0.0993 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "Epoch 18/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9545\n",
      "Epoch 18: val_loss did not improve from 0.09934\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "737/737 [==============================] - 679s 921ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 0.1045 - val_accuracy: 0.9728 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.09934\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "737/737 [==============================] - 679s 921ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 0.1045 - val_accuracy: 0.9728 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "Epoch 19/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9568\n",
      "Epoch 19: val_loss did not improve from 0.09934\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1388 - accuracy: 0.9568 - val_loss: 0.1009 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.09934\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1388 - accuracy: 0.9568 - val_loss: 0.1009 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 20/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9584\n",
      "Epoch 20: val_loss did not improve from 0.09934\n",
      "737/737 [==============================] - 684s 928ms/step - loss: 0.1357 - accuracy: 0.9584 - val_loss: 0.1009 - val_accuracy: 0.9721 - lr: 2.5000e-04\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.09934\n",
      "737/737 [==============================] - 684s 928ms/step - loss: 0.1357 - accuracy: 0.9584 - val_loss: 0.1009 - val_accuracy: 0.9721 - lr: 2.5000e-04\n",
      "Epoch 21/40\n",
      "Epoch 21/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9571\n",
      "Epoch 21: val_loss improved from 0.09934 to 0.09933, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.09934 to 0.09933, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "737/737 [==============================] - 30971s 42s/step - loss: 0.1404 - accuracy: 0.9571 - val_loss: 0.0993 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "737/737 [==============================] - 30971s 42s/step - loss: 0.1404 - accuracy: 0.9571 - val_loss: 0.0993 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 22/40\n",
      "Epoch 22/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9592\n",
      "Epoch 22: val_loss improved from 0.09933 to 0.09889, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.09933 to 0.09889, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 840s 1s/step - loss: 0.1309 - accuracy: 0.9592 - val_loss: 0.0989 - val_accuracy: 0.9732 - lr: 1.2500e-04\n",
      "737/737 [==============================] - 840s 1s/step - loss: 0.1309 - accuracy: 0.9592 - val_loss: 0.0989 - val_accuracy: 0.9732 - lr: 1.2500e-04\n",
      "Epoch 23/40\n",
      "Epoch 23/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9596\n",
      "Epoch 23: val_loss did not improve from 0.09889\n",
      "737/737 [==============================] - 688s 934ms/step - loss: 0.1310 - accuracy: 0.9596 - val_loss: 0.0996 - val_accuracy: 0.9717 - lr: 1.2500e-04\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.09889\n",
      "737/737 [==============================] - 688s 934ms/step - loss: 0.1310 - accuracy: 0.9596 - val_loss: 0.0996 - val_accuracy: 0.9717 - lr: 1.2500e-04\n",
      "Epoch 24/40\n",
      "Epoch 24/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9603\n",
      "Epoch 24: val_loss did not improve from 0.09889\n",
      "737/737 [==============================] - 726s 985ms/step - loss: 0.1294 - accuracy: 0.9603 - val_loss: 0.0990 - val_accuracy: 0.9732 - lr: 1.2500e-04\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.09889\n",
      "737/737 [==============================] - 726s 985ms/step - loss: 0.1294 - accuracy: 0.9603 - val_loss: 0.0990 - val_accuracy: 0.9732 - lr: 1.2500e-04\n",
      "Epoch 25/40\n",
      "Epoch 25/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9601\n",
      "Epoch 25: val_loss did not improve from 0.09889\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "737/737 [==============================] - 2638s 4s/step - loss: 0.1303 - accuracy: 0.9601 - val_loss: 0.0991 - val_accuracy: 0.9717 - lr: 1.2500e-04\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.09889\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "737/737 [==============================] - 2638s 4s/step - loss: 0.1303 - accuracy: 0.9601 - val_loss: 0.0991 - val_accuracy: 0.9717 - lr: 1.2500e-04\n",
      "Epoch 26/40\n",
      "Epoch 26/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9592\n",
      "Epoch 26: val_loss improved from 0.09889 to 0.09822, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.09889 to 0.09822, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 686s 930ms/step - loss: 0.1302 - accuracy: 0.9592 - val_loss: 0.0982 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "737/737 [==============================] - 686s 930ms/step - loss: 0.1302 - accuracy: 0.9592 - val_loss: 0.0982 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "Epoch 27/40\n",
      "Epoch 27/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9596\n",
      "Epoch 27: val_loss did not improve from 0.09822\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1314 - accuracy: 0.9596 - val_loss: 0.0983 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "Epoch 28/40\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.09822\n",
      "737/737 [==============================] - 680s 922ms/step - loss: 0.1314 - accuracy: 0.9596 - val_loss: 0.0983 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "Epoch 28/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9612\n",
      "Epoch 28: val_loss improved from 0.09822 to 0.09806, saving model to ../models/efficientnet_transfer_best.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.09822 to 0.09806, saving model to ../models/efficientnet_transfer_best.h5\n",
      "737/737 [==============================] - 890s 1s/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.0981 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "737/737 [==============================] - 890s 1s/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.0981 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "Epoch 29/40\n",
      "Epoch 29/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9625\n",
      "Epoch 29: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 956s 1s/step - loss: 0.1267 - accuracy: 0.9625 - val_loss: 0.0989 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 956s 1s/step - loss: 0.1267 - accuracy: 0.9625 - val_loss: 0.0989 - val_accuracy: 0.9728 - lr: 6.2500e-05\n",
      "Epoch 30/40\n",
      "Epoch 30/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9595\n",
      "Epoch 30: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 725s 984ms/step - loss: 0.1281 - accuracy: 0.9595 - val_loss: 0.0992 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 725s 984ms/step - loss: 0.1281 - accuracy: 0.9595 - val_loss: 0.0992 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "Epoch 31/40\n",
      "Epoch 31/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9605\n",
      "Epoch 31: val_loss did not improve from 0.09806\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "737/737 [==============================] - 745s 1s/step - loss: 0.1264 - accuracy: 0.9605 - val_loss: 0.0993 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.09806\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "737/737 [==============================] - 745s 1s/step - loss: 0.1264 - accuracy: 0.9605 - val_loss: 0.0993 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "Epoch 32/40\n",
      "Epoch 32/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9612\n",
      "Epoch 32: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 735s 997ms/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.0991 - val_accuracy: 0.9728 - lr: 3.1250e-05\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 735s 997ms/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.0991 - val_accuracy: 0.9728 - lr: 3.1250e-05\n",
      "Epoch 33/40\n",
      "Epoch 33/40\n",
      "737/737 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9619Restoring model weights from the end of the best epoch: 28.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 724s 981ms/step - loss: 0.1218 - accuracy: 0.9619 - val_loss: 0.0984 - val_accuracy: 0.9732 - lr: 3.1250e-05\n",
      "Epoch 33: early stopping\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.09806\n",
      "737/737 [==============================] - 724s 981ms/step - loss: 0.1218 - accuracy: 0.9619 - val_loss: 0.0984 - val_accuracy: 0.9732 - lr: 3.1250e-05\n",
      "Epoch 33: early stopping\n",
      "‚úÖ EfficientNetB7 training completed!\n",
      "   Best validation accuracy: 0.9748\n",
      "   Test accuracy: 1.0000\n",
      "   Test loss: 0.0043\n",
      "\n",
      "üéâ All models trained successfully!\n",
      "‚úÖ EfficientNetB7 training completed!\n",
      "   Best validation accuracy: 0.9748\n",
      "   Test accuracy: 1.0000\n",
      "   Test loss: 0.0043\n",
      "\n",
      "üéâ All models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "input_shape = (img_height, img_width, 3)\n",
    "num_classes = len(class_names)\n",
    "EPOCHS = 40  # Fewer epochs for transfer learning\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"- Input shape: {input_shape}\")\n",
    "print(f\"- Number of classes: {num_classes}\")\n",
    "print(f\"- Epochs: {EPOCHS}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"- Batch size: {batch_size}\")\n",
    "\n",
    "# Store results for comparison\n",
    "results = {}\n",
    "\n",
    "# Train each model\n",
    "for config in model_configs:\n",
    "    model_name = config['name']\n",
    "    display_name = config['display_name']\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training {display_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create model\n",
    "    model, base_model = create_transfer_model(\n",
    "        model_name, input_shape, num_classes, trainable=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Model created:\")\n",
    "    print(f\"- Total parameters: {model.count_params():,}\")\n",
    "    print(f\"- Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")\n",
    "    print(f\"- Frozen parameters: {base_model.count_params():,}\")\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'../models/{model_name}_transfer_best.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Starting training...\")\n",
    "    train_ds.reset()\n",
    "    val_ds.reset()\n",
    "    model.summary() \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_ds.reset()\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'display_name': display_name,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_loss': test_loss,\n",
    "        'total_params': model.count_params(),\n",
    "        'trainable_params': sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {display_name} training completed!\")\n",
    "    print(f\"   Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"   Test accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"   Test loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Reset generators\n",
    "    train_ds.reset()\n",
    "    val_ds.reset()\n",
    "    test_ds.reset()\n",
    "\n",
    "print(f\"\\nüéâ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fddb5",
   "metadata": {},
   "source": [
    "## 5. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFER LEARNING MODELS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': result['display_name'],\n",
    "        'Best Val Accuracy': f\"{result['best_val_accuracy']:.4f}\",\n",
    "        'Test Accuracy': f\"{result['test_accuracy']:.4f}\",\n",
    "        'Test Loss': f\"{result['test_loss']:.4f}\"\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['test_accuracy'])\n",
    "best_result = results[best_model_name]\n",
    "\n",
    "print(f\"\\nBest performing model: {best_result['display_name']}\")\n",
    "print(f\"Test accuracy: {best_result['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of all models\n",
    "plot_model_comparison(results)\n",
    "\n",
    "# Create performance comparison chart\n",
    "def plot_performance_comparison(results, finetune_accuracy=None):\n",
    "    \"\"\"Create a bar chart comparing model performances.\"\"\"\n",
    "    \n",
    "    model_names = [results[k]['display_name'] for k in results.keys()]\n",
    "    test_accuracies = [results[k]['test_accuracy'] for k in results.keys()]\n",
    "    val_accuracies = [results[k]['best_val_accuracy'] for k in results.keys()]\n",
    "    \n",
    "    if finetune_accuracy is not None:\n",
    "        model_names.append(f\"{best_result['display_name']} (Fine-tuned)\")\n",
    "        test_accuracies.append(finetune_accuracy)\n",
    "        val_accuracies.append(finetune_accuracy)  # Assuming same for display\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bars1 = ax.bar(x - width/2, val_accuracies, width, label='Best Validation Accuracy', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, test_accuracies, width, label='Test Accuracy', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Transfer Learning Models Performance Comparison', fontweight='bold', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    def autolabel(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                       xytext=(0, 3),  # 3 points vertical offset\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "    \n",
    "    autolabel(bars1)\n",
    "    autolabel(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot performance comparison (will update after fine-tuning)\n",
    "plot_performance_comparison(results, finetune_test_accuracy if 'finetune_test_accuracy' in locals() else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f38d6a",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba74844",
   "metadata": {},
   "source": [
    "## 7. Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe60a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fine-tuned model as the best model\n",
    "best_model = finetune_model\n",
    "best_model_name_display = f\"{best_result['display_name']} (Fine-tuned)\"\n",
    "\n",
    "print(f\"üèÜ Best Model: {best_model_name_display}\")\n",
    "print(f\"üìä Detailed Evaluation on Test Set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate predictions on test set\n",
    "test_ds.reset()\n",
    "print(\"Generating predictions on test set...\")\n",
    "y_pred = best_model.predict(test_ds, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels from test generator\n",
    "test_ds.reset()\n",
    "y_true_classes = []\n",
    "for i in range(len(test_ds)):\n",
    "    batch_images, batch_labels = next(test_ds)\n",
    "    batch_true_classes = np.argmax(batch_labels, axis=1)\n",
    "    y_true_classes.extend(batch_true_classes)\n",
    "\n",
    "y_true_classes = np.array(y_true_classes)\n",
    "\n",
    "# Ensure we have the same number of predictions and true labels\n",
    "min_length = min(len(y_pred_classes), len(y_true_classes))\n",
    "y_pred_classes = y_pred_classes[:min_length]\n",
    "y_true_classes = y_true_classes[:min_length]\n",
    "\n",
    "print(f\"Number of test samples evaluated: {min_length}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nüìã Classification Report - {best_model_name_display}:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Reset generator\n",
    "test_ds.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ec01e",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix and Per-Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_names, yticklabels=class_names,\n",
    "           cbar_kws={'label': 'Number of Samples'})\n",
    "plt.title(f'Confusion Matrix - {best_model_name_display}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class metrics\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\nüìä Per-Class Performance Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Class':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    support = cm.sum(axis=1)[i]\n",
    "    print(f\"{class_name:<15} {class_accuracy[i]:<10.4f} {precision[i]:<10.4f} \"\n",
    "          f\"{recall[i]:<10.4f} {f1_score[i]:<10.4f} {support:<10}\")\n",
    "\n",
    "# Overall metrics\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1 = np.mean(f1_score)\n",
    "weighted_precision = np.average(precision, weights=cm.sum(axis=1))\n",
    "weighted_recall = np.average(recall, weights=cm.sum(axis=1))\n",
    "weighted_f1 = np.average(f1_score, weights=cm.sum(axis=1))\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Macro Avg':<15} {macro_precision:<10.4f} {macro_precision:<10.4f} \"\n",
    "      f\"{macro_recall:<10.4f} {macro_f1:<10.4f} {cm.sum():<10}\")\n",
    "print(f\"{'Weighted Avg':<15} {weighted_precision:<10.4f} {weighted_precision:<10.4f} \"\n",
    "      f\"{weighted_recall:<10.4f} {weighted_f1:<10.4f} {cm.sum():<10}\")\n",
    "\n",
    "print(f\"\\nüéØ Overall Test Accuracy: {finetune_test_accuracy:.4f}\")\n",
    "\n",
    "# Find best and worst performing classes\n",
    "best_class_idx = np.argmax(class_accuracy)\n",
    "worst_class_idx = np.argmin(class_accuracy)\n",
    "\n",
    "print(f\"\\nüìà Best performing class: {class_names[best_class_idx]} ({class_accuracy[best_class_idx]:.4f})\")\n",
    "print(f\"üìâ Worst performing class: {class_names[worst_class_idx]} ({class_accuracy[worst_class_idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c7b90",
   "metadata": {},
   "source": [
    "## 9. Model Saving and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and create comprehensive summary\n",
    "print(\"üíæ SAVING BEST MODEL AND RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "test_accuracy_str = f\"{finetune_test_accuracy:.2f}\".replace('.', '_')\n",
    "final_model_filename = f'../models/transfer_learning_final_acc_{test_accuracy_str}.h5'\n",
    "best_model.save(final_model_filename)\n",
    "print(f\"‚úÖ Final model saved as: {final_model_filename}\")\n",
    "\n",
    "# Save training histories\n",
    "import pickle\n",
    "\n",
    "# Save all model histories\n",
    "for model_name, result in results.items():\n",
    "    with open(f'../models/{model_name}_transfer_history.pkl', 'wb') as f:\n",
    "        pickle.dump(result['history'].history, f)\n",
    "    print(f\"üìà {result['display_name']} training history saved\")\n",
    "\n",
    "# Save fine-tuning history\n",
    "with open(f'../models/{best_model_name}_finetune_history.pkl', 'wb') as f:\n",
    "    pickle.dump(finetune_history.history, f)\n",
    "print(f\"üìà Fine-tuning history saved\")\n",
    "\n",
    "# Create comprehensive model configuration\n",
    "model_config = {\n",
    "    'experiment_name': 'Transfer Learning Comparison',\n",
    "    'dataset': 'Animals10',\n",
    "    'input_shape': list(input_shape),\n",
    "    'num_classes': num_classes,\n",
    "    'batch_size': batch_size,\n",
    "    'class_names': class_names,\n",
    "    \n",
    "    # Model comparison results\n",
    "    'models_compared': {\n",
    "        model_name: {\n",
    "            'display_name': result['display_name'],\n",
    "            'best_val_accuracy': float(result['best_val_accuracy']),\n",
    "            'test_accuracy': float(result['test_accuracy']),\n",
    "            'test_loss': float(result['test_loss']),\n",
    "            'total_parameters': int(result['total_params']),\n",
    "            'trainable_parameters': int(result['trainable_params'])\n",
    "        } for model_name, result in results.items()\n",
    "    },\n",
    "    \n",
    "    # Best model details\n",
    "    'best_model': {\n",
    "        'name': best_model_name,\n",
    "        'display_name': best_result['display_name'],\n",
    "        'base_test_accuracy': float(best_result['test_accuracy']),\n",
    "        'finetuned_test_accuracy': float(finetune_test_accuracy),\n",
    "        'improvement_from_finetuning': float(finetune_test_accuracy - best_result['test_accuracy']),\n",
    "        'total_parameters': int(best_model.count_params()),\n",
    "        'trainable_parameters': int(sum([tf.keras.backend.count_params(w) for w in best_model.trainable_weights])),\n",
    "        'frozen_parameters': int(best_model.count_params() - sum([tf.keras.backend.count_params(w) for w in best_model.trainable_weights]))\n",
    "    },\n",
    "    \n",
    "    # Training configuration\n",
    "    'training_config': {\n",
    "        'initial_epochs': EPOCHS,\n",
    "        'initial_learning_rate': LEARNING_RATE,\n",
    "        'finetune_epochs': FINETUNE_EPOCHS,\n",
    "        'finetune_learning_rate': FINETUNE_LR,\n",
    "        'early_stopping_patience': 10,\n",
    "        'reduce_lr_patience': 5\n",
    "    },\n",
    "    \n",
    "    # Performance metrics\n",
    "    'final_performance': {\n",
    "        'test_accuracy': float(finetune_test_accuracy),\n",
    "        'test_loss': float(finetune_test_loss),\n",
    "        'macro_precision': float(macro_precision),\n",
    "        'macro_recall': float(macro_recall),\n",
    "        'macro_f1': float(macro_f1),\n",
    "        'weighted_precision': float(weighted_precision),\n",
    "        'weighted_recall': float(weighted_recall),\n",
    "        'weighted_f1': float(weighted_f1)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "import json\n",
    "with open(f'../models/transfer_learning_final_config.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "print(f\"‚öôÔ∏è  Model configuration saved\")\n",
    "\n",
    "# Final Results Summary\n",
    "print(f\"\\nüèÜ TRANSFER LEARNING EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset: Animals10 ({num_classes} classes)\")\n",
    "print(f\"Total samples: {train_ds.samples + val_ds.samples + test_ds.samples:,}\")\n",
    "print(f\"Training samples: {train_ds.samples:,}\")\n",
    "print(f\"Validation samples: {val_ds.samples:,}\")\n",
    "print(f\"Test samples: {test_ds.samples:,}\")\n",
    "\n",
    "print(f\"\\nüìä Model Comparison Results:\")\n",
    "for model_name, result in results.items():\n",
    "    print(f\"  {result['display_name']:<15}: {result['test_accuracy']:.4f} test accuracy\")\n",
    "\n",
    "print(f\"\\nüéØ Best Model: {best_result['display_name']}\")\n",
    "print(f\"  Initial test accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"  Fine-tuned test accuracy: {finetune_test_accuracy:.4f}\")\n",
    "print(f\"  Improvement from fine-tuning: {finetune_test_accuracy - best_result['test_accuracy']:+.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Model Architecture:\")\n",
    "print(f\"  Base model: {best_result['display_name']} (pre-trained on ImageNet)\")\n",
    "print(f\"  Total parameters: {best_model.count_params():,}\")\n",
    "print(f\"  Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in best_model.trainable_weights]):,}\")\n",
    "print(f\"  Frozen parameters: {best_model.count_params() - sum([tf.keras.backend.count_params(w) for w in best_model.trainable_weights]):,}\")\n",
    "\n",
    "print(f\"\\nüìà Training Efficiency:\")\n",
    "total_epochs = len(best_result['history'].history['accuracy']) + len(finetune_history.history['accuracy'])\n",
    "print(f\"  Total epochs trained: {total_epochs}\")\n",
    "print(f\"  Initial training epochs: {len(best_result['history'].history['accuracy'])}\")\n",
    "print(f\"  Fine-tuning epochs: {len(finetune_history.history['accuracy'])}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All files saved to ../models/ directory\")\n",
    "print(f\"   - Final model: {final_model_filename}\")\n",
    "print(f\"   - Training histories: *_history.pkl files\")\n",
    "print(f\"   - Configuration: transfer_learning_final_config.json\")\n",
    "\n",
    "if finetune_test_accuracy > 0.7:\n",
    "    print(f\"\\nüéâ SUCCESS: Achieved target accuracy > 70%!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Target accuracy (70%) not reached. Consider:\")\n",
    "    print(f\"   - More training epochs\")\n",
    "    print(f\"   - Different data augmentation\")\n",
    "    print(f\"   - Learning rate adjustment\")\n",
    "    print(f\"   - Different pre-trained model\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d8457",
   "metadata": {},
   "source": [
    "## 10. Model Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a few sample predictions for deployment verification\n",
    "print(\"üöÄ DEPLOYMENT PREPARATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_single_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess a single image for model prediction.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "    \n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Same normalization as training\n",
    "    return img_array\n",
    "\n",
    "# Function to predict class for a single image\n",
    "def predict_single_image(model, image_path, class_names, top_k=3):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image and return top-k predictions.\n",
    "    \"\"\"\n",
    "    img_array = preprocess_single_image(image_path)\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    top_indices = predictions[0].argsort()[-top_k:][::-1]\n",
    "    top_predictions = []\n",
    "    \n",
    "    for idx in top_indices:\n",
    "        confidence = predictions[0][idx]\n",
    "        class_name = class_names[idx]\n",
    "        top_predictions.append({\n",
    "            'class': class_name,\n",
    "            'confidence': float(confidence),\n",
    "            'percentage': f\"{confidence*100:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    return top_predictions\n",
    "\n",
    "# Test with a few random images from test set\n",
    "test_ds.reset()\n",
    "sample_batch_x, sample_batch_y = next(test_ds)\n",
    "sample_indices = np.random.choice(len(sample_batch_x), 3, replace=False)\n",
    "\n",
    "print(\"üì∏ Testing model with sample images:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    true_class_idx = np.argmax(sample_batch_y[idx])\n",
    "    true_class = class_names[true_class_idx]\n",
    "    \n",
    "    # Make prediction\n",
    "    img_for_prediction = np.expand_dims(sample_batch_x[idx], axis=0)\n",
    "    prediction = best_model.predict(img_for_prediction, verbose=0)\n",
    "    predicted_class_idx = np.argmax(prediction)\n",
    "    predicted_class = class_names[predicted_class_idx]\n",
    "    confidence = prediction[0][predicted_class_idx]\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  True class: {true_class}\")\n",
    "    print(f\"  Predicted: {predicted_class} ({confidence*100:.2f}% confidence)\")\n",
    "    print(f\"  Correct: {'‚úÖ' if predicted_class == true_class else '‚ùå'}\")\n",
    "    print()\n",
    "\n",
    "# Create a simple deployment helper function\n",
    "def create_deployment_helper():\n",
    "    \"\"\"\n",
    "    Create a simple deployment helper script.\n",
    "    \"\"\"\n",
    "    deployment_code = f'''\n",
    "# Model Deployment Helper\n",
    "# Generated from Transfer Learning notebook\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Model and class information\n",
    "MODEL_PATH = \"{final_model_filename}\"\n",
    "CLASS_NAMES = {class_names}\n",
    "IMG_HEIGHT = {img_height}\n",
    "IMG_WIDTH = {img_width}\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the trained model.\"\"\"\n",
    "    return tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess image for prediction.\"\"\"\n",
    "    img = image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "def predict_image(model, image_path, top_k=3):\n",
    "    \"\"\"Predict class for a single image.\"\"\"\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    top_indices = predictions[0].argsort()[-top_k:][::-1]\n",
    "    results = []\n",
    "    \n",
    "    for idx in top_indices:\n",
    "        results.append({{\n",
    "            'class': CLASS_NAMES[idx],\n",
    "            'confidence': float(predictions[0][idx]),\n",
    "            'percentage': f\"{{predictions[0][idx]*100:.2f}}%\"\n",
    "        }})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# model = load_model()\n",
    "# predictions = predict_image(model, \"path/to/image.jpg\")\n",
    "# print(f\"Predicted class: {{predictions[0]['class']}} ({{predictions[0]['percentage']}})\")\n",
    "'''\n",
    "    \n",
    "    with open('../models/deployment_helper.py', 'w') as f:\n",
    "        f.write(deployment_code)\n",
    "    \n",
    "    print(\"üìÑ Deployment helper script created: ../models/deployment_helper.py\")\n",
    "\n",
    "create_deployment_helper()\n",
    "\n",
    "# Create model summary for documentation\n",
    "model_summary = {\n",
    "    'model_name': f'{best_result[\"display_name\"]} Transfer Learning',\n",
    "    'test_accuracy': f'{finetune_test_accuracy:.4f}',\n",
    "    'model_file': final_model_filename,\n",
    "    'input_shape': f'{img_height}x{img_width}x3',\n",
    "    'output_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    'preprocessing': 'Normalize pixel values to [0,1]',\n",
    "    'deployment_ready': True\n",
    "}\n",
    "\n",
    "print(f\"\\\\nüìã DEPLOYMENT SUMMARY:\")\n",
    "print(f\"  Model accuracy: {finetune_test_accuracy:.4f}\")\n",
    "print(f\"  Model file: {final_model_filename}\")\n",
    "print(f\"  Input size: {img_height}x{img_width} pixels\")\n",
    "print(f\"  Classes: {num_classes} animal categories\")\n",
    "print(f\"  Preprocessing: Normalize to [0,1]\")\n",
    "print(f\"  Deployment files created: ‚úÖ\")\n",
    "\n",
    "print(f\"\\\\nüéâ Transfer learning experiment completed successfully!\")\n",
    "print(f\"   The model is ready for deployment in a Flask application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6979493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the best performing model\n",
    "print(f\"\\nüéØ Fine-tuning {best_result['display_name']}...\")\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "finetune_model, base_model = create_transfer_model(\n",
    "    best_model_name, input_shape, num_classes, trainable=True\n",
    ")\n",
    "\n",
    "# Load the best weights from initial training\n",
    "finetune_model.load_weights(f'../models/{best_model_name}_transfer_best.h5')\n",
    "\n",
    "# Use a lower learning rate for fine-tuning\n",
    "FINETUNE_LR = 1e-5  # Much lower learning rate\n",
    "finetune_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=FINETUNE_LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning configuration:\")\n",
    "print(f\"- Model: {best_result['display_name']}\")\n",
    "print(f\"- Learning rate: {FINETUNE_LR}\")\n",
    "print(f\"- Total parameters: {finetune_model.count_params():,}\")\n",
    "print(f\"- Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in finetune_model.trainable_weights]):,}\")\n",
    "\n",
    "# Setup callbacks for fine-tuning\n",
    "finetune_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        f'../models/{best_model_name}_finetuned_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Fine-tune for fewer epochs\n",
    "FINETUNE_EPOCHS = 15\n",
    "\n",
    "print(f\"\\nüöÄ Starting fine-tuning for {FINETUNE_EPOCHS} epochs...\")\n",
    "train_ds.reset()\n",
    "val_ds.reset()\n",
    "\n",
    "finetune_history = finetune_model.fit(\n",
    "    train_ds,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=finetune_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "test_ds.reset()\n",
    "finetune_test_loss, finetune_test_accuracy = finetune_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "print(f\"\\n‚úÖ Fine-tuning completed!\")\n",
    "print(f\"Original test accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Fine-tuned test accuracy: {finetune_test_accuracy:.4f}\")\n",
    "print(f\"Improvement: {finetune_test_accuracy - best_result['test_accuracy']:+.4f}\")\n",
    "\n",
    "# Reset generators\n",
    "train_ds.reset()\n",
    "val_ds.reset()\n",
    "test_ds.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
