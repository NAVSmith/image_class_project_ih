{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a0c5bf",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification\n",
    "\n",
    "This notebook implements transfer learning using pre-trained models (VGG16, ResNet50, EfficientNet).\n",
    "\n",
    "## Objectives:\n",
    "- Compare multiple pre-trained architectures\n",
    "- Implement transfer learning with frozen base layers\n",
    "- Fine-tune the best performing model\n",
    "- Compare results with custom CNN\n",
    "- Select the best overall model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fffe3",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120676e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import pickle\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca61d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data (same as previous notebooks)\n",
    "DATASET_CHOICE = \"cifar10\"  # or \"animals10\"\n",
    "\n",
    "if DATASET_CHOICE == \"cifar10\":\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    num_classes = 10\n",
    "\n",
    "# Normalize and prepare data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Train/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    x_train, y_train_cat, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set: {x_train_split.shape}\")\n",
    "print(f\"Validation set: {x_val_split.shape}\")\n",
    "print(f\"Test set: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a31c59",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images for pre-trained models (they expect larger input sizes)\n",
    "def resize_images(images, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize images to target size for pre-trained models.\n",
    "    \"\"\"\n",
    "    resized = tf.image.resize(images, target_size)\n",
    "    return resized.numpy()\n",
    "\n",
    "# Resize all datasets\n",
    "x_train_resized = resize_images(x_train_split)\n",
    "x_val_resized = resize_images(x_val_split)\n",
    "x_test_resized = resize_images(x_test)\n",
    "\n",
    "print(f\"Resized training set: {x_train_resized.shape}\")\n",
    "print(f\"Resized validation set: {x_val_resized.shape}\")\n",
    "print(f\"Resized test set: {x_test_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for transfer learning\n",
    "transfer_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "transfer_datagen.fit(x_train_resized)\n",
    "print(\"Data augmentation configured for transfer learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e890e31",
   "metadata": {},
   "source": [
    "## 3. Transfer Learning Model Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(base_model_name, input_shape, num_classes, trainable=False):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model with specified base architecture.\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: 'vgg16', 'resnet50', or 'efficientnet'\n",
    "        input_shape: Input image shape\n",
    "        num_classes: Number of output classes\n",
    "        trainable: Whether to make base model trainable (for fine-tuning)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select base model\n",
    "    if base_model_name == 'vgg16':\n",
    "        base_model = VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name == 'resnet50':\n",
    "        base_model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name == 'efficientnet':\n",
    "        base_model = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze or unfreeze base model\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "print(\"Transfer learning model creation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6ee9",
   "metadata": {},
   "source": [
    "## 4. Compare Multiple Pre-trained Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02174a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations to compare\n",
    "model_configs = [\n",
    "    {'name': 'vgg16', 'display_name': 'VGG16'},\n",
    "    {'name': 'resnet50', 'display_name': 'ResNet50'},\n",
    "    {'name': 'efficientnet', 'display_name': 'EfficientNetB0'}\n",
    "]\n",
    "\n",
    "input_shape = x_train_resized.shape[1:]  # (224, 224, 3)\n",
    "results = {}\n",
    "\n",
    "print(f\"Input shape for transfer learning: {input_shape}\")\n",
    "print(f\"Will compare {len(model_configs)} architectures...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b929695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 20  # Fewer epochs for initial comparison\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config['name']\n",
    "    display_name = config['display_name']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {display_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model, base_model = create_transfer_model(\n",
    "        model_name, input_shape, num_classes, trainable=False\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'../models/{model_name}_transfer_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"Model parameters: {model.count_params():,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.trainable_variables):,}\")\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        transfer_datagen.flow(x_train_resized, y_train_split, batch_size=BATCH_SIZE),\n",
    "        steps_per_epoch=len(x_train_resized) // BATCH_SIZE,\n",
    "        epochs=INITIAL_EPOCHS,\n",
    "        validation_data=(x_val_resized, y_val_split),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(x_test_resized, y_test_cat, verbose=0)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'history': history.history,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_loss': test_loss,\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'display_name': display_name\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{display_name} Results:\")\n",
    "    print(f\"Best validation accuracy: {results[model_name]['best_val_accuracy']:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nAll models trained and evaluated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fddb5",
   "metadata": {},
   "source": [
    "## 5. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFER LEARNING MODELS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': result['display_name'],\n",
    "        'Best Val Accuracy': f\"{result['best_val_accuracy']:.4f}\",\n",
    "        'Test Accuracy': f\"{result['test_accuracy']:.4f}\",\n",
    "        'Test Loss': f\"{result['test_loss']:.4f}\"\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['test_accuracy'])\n",
    "best_result = results[best_model_name]\n",
    "\n",
    "print(f\"\\nBest performing model: {best_result['display_name']}\")\n",
    "print(f\"Test accuracy: {best_result['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of training histories\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot validation accuracy comparison\n",
    "for model_name, result in results.items():\n",
    "    axes[0, 0].plot(result['history']['val_accuracy'], \n",
    "                   label=result['display_name'], linewidth=2)\n",
    "axes[0, 0].set_title('Validation Accuracy Comparison')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation loss comparison\n",
    "for model_name, result in results.items():\n",
    "    axes[0, 1].plot(result['history']['val_loss'], \n",
    "                   label=result['display_name'], linewidth=2)\n",
    "axes[0, 1].set_title('Validation Loss Comparison')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot of final test accuracies\n",
    "model_names = [results[k]['display_name'] for k in results.keys()]\n",
    "test_accuracies = [results[k]['test_accuracy'] for k in results.keys()]\n",
    "\n",
    "bars = axes[1, 0].bar(model_names, test_accuracies, \n",
    "                     color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1, 0].set_title('Test Accuracy Comparison')\n",
    "axes[1, 0].set_ylabel('Test Accuracy')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, test_accuracies):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                   f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Training vs validation accuracy for best model\n",
    "best_history = best_result['history']\n",
    "axes[1, 1].plot(best_history['accuracy'], label='Training', linewidth=2)\n",
    "axes[1, 1].plot(best_history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title(f'{best_result[\"display_name\"]} - Best Model Training')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f38d6a",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6979493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the best performing model\n",
    "print(f\"\\nFine-tuning {best_result['display_name']}...\")\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "finetune_model, base_model = create_transfer_model(\n",
    "    best_model_name, input_shape, num_classes, trainable=True\n",
    ")\n",
    "\n",
    "# Load the best weights from initial training\n",
    "finetune_model.load_weights(f'../models/{best_model_name}_transfer_best.h5')\n",
    "\n",
    "# Use a lower learning rate for fine-tuning\n",
    "finetune_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Lower LR\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning model with {finetune_model.count_params():,} total parameters\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in finetune_model.trainable_variables):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning callbacks\n",
    "finetune_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        f'../models/{best_model_name}_finetuned_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Fine-tune the model\n",
    "FINETUNE_EPOCHS = 30\n",
    "\n",
    "finetune_history = finetune_model.fit(\n",
    "    transfer_datagen.flow(x_train_resized, y_train_split, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=len(x_train_resized) // BATCH_SIZE,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=(x_val_resized, y_val_split),\n",
    "    callbacks=finetune_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76e1ab",
   "metadata": {},
   "source": [
    "## 7. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model\n",
    "finetune_test_loss, finetune_test_accuracy = finetune_model.evaluate(\n",
    "    x_test_resized, y_test_cat, verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Results Comparison:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Initial {best_result['display_name']}: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Fine-tuned {best_result['display_name']}: {finetune_test_accuracy:.4f}\")\n",
    "print(f\"Improvement: {finetune_test_accuracy - best_result['test_accuracy']:+.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Generate detailed predictions for fine-tuned model\n",
    "y_pred_finetune = finetune_model.predict(x_test_resized)\n",
    "y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
    "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report (Fine-tuned Model):\")\n",
    "print(classification_report(y_true_classes, y_pred_classes_finetune, \n",
    "                          target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for fine-tuned model\n",
    "cm_finetune = confusion_matrix(y_true_classes, y_pred_classes_finetune)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_finetune, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - Fine-tuned {best_result[\"display_name\"]}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy_finetune = cm_finetune.diagonal() / cm_finetune.sum(axis=1)\n",
    "print(\"\\nPer-class Accuracy (Fine-tuned):\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {class_accuracy_finetune[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516928ae",
   "metadata": {},
   "source": [
    "## 8. Model Comparison with Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom CNN results for comparison (if available)\n",
    "try:\n",
    "    with open(f'../models/custom_cnn_{DATASET_CHOICE}_history.pkl', 'rb') as f:\n",
    "        custom_cnn_history = pickle.load(f)\n",
    "    \n",
    "    # Load custom CNN model to get test accuracy\n",
    "    custom_cnn_model = keras.models.load_model(f'../models/custom_cnn_{DATASET_CHOICE}_final.h5')\n",
    "    custom_cnn_test_loss, custom_cnn_test_accuracy = custom_cnn_model.evaluate(\n",
    "        x_test, y_test_cat, verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFINAL MODEL COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Custom CNN Test Accuracy: {custom_cnn_test_accuracy:.4f}\")\n",
    "    print(f\"Transfer Learning ({best_result['display_name']}) Test Accuracy: {finetune_test_accuracy:.4f}\")\n",
    "    \n",
    "    if finetune_test_accuracy > custom_cnn_test_accuracy:\n",
    "        print(f\"\\n🏆 WINNER: Transfer Learning ({best_result['display_name']})\")\n",
    "        print(f\"Improvement over Custom CNN: {finetune_test_accuracy - custom_cnn_test_accuracy:+.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n🏆 WINNER: Custom CNN\")\n",
    "        print(f\"Advantage over Transfer Learning: {custom_cnn_test_accuracy - finetune_test_accuracy:+.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nCustom CNN results not found. Run notebook 02_custom_cnn.ipynb first for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a175daa",
   "metadata": {},
   "source": [
    "## 9. Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best transfer learning model\n",
    "final_model_path = f'../models/best_transfer_model_{DATASET_CHOICE}.h5'\n",
    "finetune_model.save(final_model_path)\n",
    "print(f\"Best transfer learning model saved: {final_model_path}\")\n",
    "\n",
    "# Save all results\n",
    "all_results = {\n",
    "    'initial_comparison': results,\n",
    "    'best_model_name': best_model_name,\n",
    "    'finetune_history': finetune_history.history,\n",
    "    'finetune_test_accuracy': finetune_test_accuracy,\n",
    "    'finetune_test_loss': finetune_test_loss\n",
    "}\n",
    "\n",
    "with open(f'../models/transfer_learning_results_{DATASET_CHOICE}.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "print(f\"Transfer learning results saved\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {DATASET_CHOICE.upper()}\")\n",
    "print(f\"Best architecture: {best_result['display_name']}\")\n",
    "print(f\"Initial transfer learning accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Fine-tuned accuracy: {finetune_test_accuracy:.4f}\")\n",
    "print(f\"Model parameters: {finetune_model.count_params():,}\")\n",
    "print(f\"Final model saved: {final_model_path}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
